{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Product Delivery Overview\n",
    "\n",
    "---\n",
    "\n",
    "This model simulates product delivery in USA. The supply chain includes three manufacturing facilities and fifteen distributors that order random amounts of the product – between 500 and 1000, uniformly distributed – each 1 to 2 days (uniformly distributed). There is a fleet of trucks in each manufacturing facility. When a manufacturing facility receives an order from a distributor, it checks the number of products in storage. If the required amount is available, it sends a loaded truck to the distributor. Otherwise, the order waits until the factory produces the sufficient number of products. Orders are queued in FIFO order.\n",
    "\n",
    "### Complexity\n",
    "\n",
    "    * The demand coming from each distribution center should be varied:\n",
    "    * Seasonal change\n",
    "    * Sudden disruptions/surge in demand\n",
    "\n",
    "### Observation space\n",
    "\n",
    "    * Inventory level at each manufacturing location\n",
    "    * Number of trucks, number of idle vs busy trucks, utilization of fleet at each location\n",
    "    * Whether manufacturing facility is open or not\n",
    "    * Average waiting time for orders placed at each manufacturer\n",
    "    * Average waiting time for all manufacturing facilities\n",
    "\n",
    "### Action space\n",
    "\n",
    "    * Production rate of each facility\n",
    "    * Number of trucks in each facility\n",
    "    * If a facility should stay open or not\n",
    "\n",
    "### Reward\n",
    "\n",
    "    * The reward is driven by minimizing the cost of average wait time across the system.\n",
    "    \n",
    "Reinforcement learning algorithms are able to understand and respond to dynamic environments, and their decisions can be game-changing for businesses operating complex distribution networks. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Start the Environment\n",
    "\n",
    "We begin by importing the necessary packages. \n",
    "\n",
    "First import the Communicator class of the supplied module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from al_rlexp_communicator import Communicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.nn.utils as U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple, deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import Actor, Critic\n",
    "from utils import sample, update_targets, OUNoise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hyperparameters\n",
    "\n",
    "## For Experience Replay\n",
    "BUFFER_SIZE = int(1e6)  # replay buffer size\n",
    "BATCH_SIZE = 128         # minibatch size\n",
    "\n",
    "## For Fixed-Q Target\n",
    "TAU = 1e-3              # for soft update of target parameters\n",
    "UPDATE_EVERY = 20       # how often to update the network. \n",
    "UPDATE_TIMES = 10       # and how many times to update\n",
    "\n",
    "# For Cumulative Reward\n",
    "GAMMA = 0.99            # discount factor\n",
    "\n",
    "## For Q Network\n",
    "LR_ACTOR = 1e-3         # learning rate of the actor\n",
    "LR_CRITIC = 1e-3        # learning rate of the critic\n",
    "\n",
    "WEIGHT_DECAY = 0        # L2 weight decay\n",
    "\n",
    "OU_SIGMA = 0.2          # Ornstein-Uhlenbeck noise parameter\n",
    "OU_THETA = 0.15         # Ornstein-Uhlenbeck noise parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_size = 23\n",
    "action_size = 9\n",
    "random_seed = 1\n",
    "random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actor Network (w/ Target Network)\n",
    "actor_local = Actor(state_size, action_size, random_seed).to(device)\n",
    "actor_target = Actor(state_size, action_size, random_seed).to(device)\n",
    "actor_optimizer = optim.Adam(actor_local.parameters(), lr=LR_ACTOR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Critic Network (w/ Target Network)\n",
    "critic_local = Critic(state_size, action_size, random_seed).to(device)\n",
    "critic_target = Critic(state_size, action_size, random_seed).to(device)\n",
    "critic_optimizer = optim.Adam(critic_local.parameters(), lr=LR_CRITIC, weight_decay=WEIGHT_DECAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_targets(critic_local, critic_target)\n",
    "update_targets(actor_local, actor_target)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some util and data variables\n",
    "mu = 0.\n",
    "replay_memory = deque(maxlen=BUFFER_SIZE)\n",
    "experience = namedtuple(\"Experience\", field_names=[\"state\", \"action\", \"reward\", \"next_state\", \"done\"])\n",
    "# Noise process\n",
    "noise = OUNoise(action_size, random_seed, mu, OU_SIGMA, OU_THETA)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will start the environment! \n",
    "\n",
    "Create a new instance of Communicator, passing the directory of the exported model folder (the one containing “model.jar”)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "com = Communicator(\"ProductDeliveryExported\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After executing this, your model will be launched in a separate process. If on Windows, you may see a terminal window pop up; you can ignore it or minimize it, but do not close it out.\n",
    "\n",
    "Communication now happens by receiving from and sending messages to the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces\n",
    "\n",
    "In this environment, each order generated at any of the distributors will determine which manufacturer can fulfill the order most quickly. A reward of `[1, -1]` is provided for each step that is calculated using a reward function built around turnaround time and cost per product. Thus, the goal of our agent is to minimizing the cost of average wait time across the system.\n",
    "\n",
    "The observation space consists of `23` variables corresponding to inventory level, number of trucks, and average waiting time at each manufacturer facility.  Each action is a vector with 3 numbers, corresponding to 3 manufacturing facilities.\n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 20\n",
      "Size of each action: 4\n",
      "There are 20 agents. Each observes a state with length: 33\n",
      "The state for the first agent looks like: [ 0.00000000e+00 -4.00000000e+00  0.00000000e+00  1.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -4.37113883e-08  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00 -1.00000000e+01  0.00000000e+00\n",
      "  1.00000000e+00 -0.00000000e+00 -0.00000000e+00 -4.37113883e-08\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  5.75471878e+00 -1.00000000e+00\n",
      "  5.55726624e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      " -1.68164849e-01]\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents\n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:', states[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Take Random Actions in the Environment (Optional Step)\n",
    "\n",
    "In the next code cell, we will learn how to use the Python API to control the agent and receive feedback from the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total score (averaged over agents) this episode: 0.135499996971339\n",
      "Total steps in this episode: 1001\n"
     ]
    }
   ],
   "source": [
    "env_info = env.reset(train_mode=False)[brain_name]     # reset the environment    \n",
    "states = env_info.vector_observations                  # get the current state (for each agent)\n",
    "scores = np.zeros(num_agents)                          # initialize the score (for each agent)\n",
    "steps = 0\n",
    "while True:\n",
    "    actions = np.random.randn(num_agents, action_size) # select an action (for each agent)\n",
    "    actions = np.clip(actions, -1, 1)                  # all actions between -1 and 1\n",
    "    env_info = env.step(actions)[brain_name]           # send all actions to tne environment\n",
    "    next_states = env_info.vector_observations         # get next state (for each agent)\n",
    "    rewards = env_info.rewards                         # get reward (for each agent)\n",
    "    dones = env_info.local_done                        # see if episode finished\n",
    "    scores += env_info.rewards                         # update the score (for each agent)\n",
    "    states = next_states                               # roll over states to next time step\n",
    "    steps += 1\n",
    "    if np.any(dones):                                  # exit loop if episode finished\n",
    "        break\n",
    "print('Total score (averaged over agents) this episode: {}'.format(np.mean(scores)))\n",
    "print('Total steps in this episode: {}'.format(steps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Define Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Agent - one of the core logic of DDPG - To run INFERENCE on Actor Neural Network\n",
    "def agent(state, add_noise=True):\n",
    "    \"\"\"Returns actions for given state as per current policy.\"\"\"\n",
    "    state = torch.from_numpy(state).float().to(device)\n",
    "    actor_local.eval()\n",
    "    with torch.no_grad():\n",
    "        action = actor_local(state).cpu().data.numpy()\n",
    "    actor_local.train()\n",
    "    if add_noise:\n",
    "        action +=noise.sample()\n",
    "    return np.clip(action, -1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Define Training of the Agent\n",
    "\n",
    "Or go straight to step 8 to test agent loaded with previuous trained weights (in its Neural Network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train Agent - One of the core logic of DDPG - To TRAIN Actor and Critic Neural NETWORK\n",
    "def train_agent(state, action, reward, next_state, done, timestep):\n",
    "    \"\"\"Update policy and value parameters using given batch of experience tuples.\n",
    "    Q_targets = r + γ * critic_target(next_state, actor_target(next_state))\n",
    "    where:\n",
    "        actor_target(state) -> action\n",
    "        critic_target(state, action) -> Q-value\n",
    "\n",
    "    Params\n",
    "    ======\n",
    "        experiences (Tuple[torch.Tensor]): tuple of (s, a, r, s', done) tuples \n",
    "        gamma (float): discount factor\n",
    "    \"\"\"\n",
    "    \"\"\"Save experience in replay memory, and use random sample from buffer to learn.\"\"\"\n",
    "       \n",
    "    e = experience(state, action, reward, next_state, done)\n",
    "    # Save experience / reward\n",
    "    replay_memory.append(e)\n",
    "        \n",
    "    # Learn, if enough samples are available in memory\n",
    "    if len(replay_memory) > BATCH_SIZE and timestep % UPDATE_EVERY == 0:\n",
    "        for _ in range(UPDATE_TIMES):\n",
    "            \n",
    "            experiences = sample(replay_memory, BATCH_SIZE)\n",
    "            states, actions, rewards, next_states, dones = experiences\n",
    "\n",
    "            # ---------------------------- update critic ---------------------------- #\n",
    "            # Get predicted next-state actions and Q values from target models\n",
    "            actions_next = actor_target(next_states)\n",
    "            Q_targets_next = critic_target(next_states, actions_next)\n",
    "            # Compute Q targets for current states (y_i)\n",
    "            Q_targets = rewards + (GAMMA * Q_targets_next * (1 - dones))\n",
    "            # Compute critic loss\n",
    "            Q_expected = critic_local(states, actions)\n",
    "            critic_loss = F.mse_loss(Q_expected, Q_targets)\n",
    "            # Minimize the loss\n",
    "            critic_optimizer.zero_grad()\n",
    "            critic_loss.backward()\n",
    "            U.clip_grad_norm_(critic_local.parameters(), 1)\n",
    "            critic_optimizer.step()\n",
    "\n",
    "\n",
    "            # ---------------------------- update actor ---------------------------- #\n",
    "            # Compute actor loss\n",
    "            actions_pred = actor_local(states)\n",
    "            actor_loss = -critic_local(states, actions_pred).mean()\n",
    "            # Minimize the loss\n",
    "            actor_optimizer.zero_grad()\n",
    "            actor_loss.backward()\n",
    "            actor_optimizer.step()\n",
    "\n",
    "            # ----------------------- update target networks ----------------------- #\n",
    "            update_targets(critic_local, critic_target, TAU)\n",
    "            update_targets(actor_local, actor_target, TAU) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Main Function - Define Training \n",
    "\n",
    "Or go straight to step 8 to test agent loaded with previuous trained weights (in its Neural Network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ddpg(n_episodes=500, max_t=1000, solved_score=30.0, consec_episodes=100, print_every=1, old_episodes=0, old_mov_avg=0.0):\n",
    "    \n",
    "    mean_scores = []                               # list of mean scores from each episode\n",
    "    min_scores = []                                # list of lowest scores from each episode\n",
    "    max_scores = []                                # list of highest scores from each episode\n",
    "    best_score = -np.inf\n",
    "    scores_deque = deque(maxlen=consec_episodes)   # mean scores from most recent episodes\n",
    "    moving_avgs = []                               # list of moving averages    \n",
    "    \n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        #reset the environment, noise and score\n",
    "        env_info = env.reset(train_mode=True)[brain_name] # reset the environment\n",
    "        states = env_info.vector_observations             # get current state for each agent\n",
    "        noise.reset()                                     # reset the noise\n",
    "        scores = np.zeros(num_agents)                     # initialize scores for each agent\n",
    "        start_time = time.time()\n",
    "        \n",
    "        for t in range(max_t):\n",
    "            actions = agent(states, add_noise=True)       # select actions with exploration\n",
    "            env_info = env.step(actions)[brain_name]      # send actions to the environment\n",
    "            next_states = env_info.vector_observations    # get next states\n",
    "            rewards = env_info.rewards                    # get the rewards \n",
    "            dones = env_info.local_done\n",
    "            \n",
    "            # save experience to replay buffer, perform learning step at defined interval\n",
    "            for state, action, reward, next_state, done in zip(states, actions, rewards, next_states, dones):            \n",
    "                train_agent(state, action, reward, next_state, done, t) # train Actor and Crtic Neural Network\n",
    "            \n",
    "            states = next_states\n",
    "            \n",
    "            scores += rewards                             # add rewards to current scores \n",
    " \n",
    "            if np.any(dones):            # exit loop when episode ends\n",
    "                break     \n",
    "        \n",
    "        duration = time.time() - start_time\n",
    "        min_scores.append(np.min(scores))             # save lowest score for a single agent\n",
    "        max_scores.append(np.max(scores))             # save highest score for a single agent        \n",
    "        mean_scores.append(np.mean(scores))           # save mean score for the episode\n",
    "        scores_deque.append(mean_scores[-1])          # save mean score to deque\n",
    "        moving_avgs.append(np.mean(scores_deque))     # save moving average     \n",
    "        \n",
    "        if i_episode % print_every == 0:\n",
    "            print('\\rEpisode {} ({} sec)  -- \\tMin: {:.1f}\\tMax: {:.1f}\\tMean: {:.1f}\\tMov. Avg: {:.1f}'.format(\\\n",
    "                  i_episode, round(duration), min_scores[-1], max_scores[-1], mean_scores[-1], moving_avgs[-1])) \n",
    "            \n",
    "        if mean_scores[-1] > best_score:\n",
    "            torch.save(actor_local.state_dict(), 'checkpoint_actor1.pth')\n",
    "            torch.save(critic_local.state_dict(), 'checkpoint_critic1.pth')  \n",
    "         \n",
    "        real_episode = i_episode + old_episodes\n",
    "        real_moving_avgs = (moving_avgs[-1]*i_episode + old_mov_avg*old_episodes)/real_episode\n",
    "        \n",
    "        if i_episode % (print_every + 3) == 0:\n",
    "            print('\\rIncluding Previous Runs -- Total Episodes {}  -- \\tReal Mov. Avg: {:.1f}'.format(\\\n",
    "                  real_episode, real_moving_avgs)) \n",
    "        \n",
    "        if real_moving_avgs >= solved_score and real_episode >= consec_episodes:\n",
    "            print('\\nEnvironment SOLVED in {} episodes!\\tMoving Average ={:.1f} over last {} episodes'.format(\\\n",
    "                                    real_episode-consec_episodes, real_moving_avgs, consec_episodes))    \n",
    "            torch.save(actor_local.state_dict(), 'checkpoint_actor1.pth')\n",
    "            torch.save(critic_local.state_dict(), 'checkpoint_critic1.pth')\n",
    "            break\n",
    "\n",
    "            \n",
    "    return mean_scores, moving_avgs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Start Training (Optional) - 1st Run\n",
    "### (Skip to step 8 to test the environment with trained agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# run the training loop\n",
    "scores, avgs = ddpg()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Continue Training (Optional) - 2nd Run\n",
    "### (Skip to step 8 to test the environment with trained agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# run the training loop with the saved weights from the previous run\n",
    "actor_local.load_state_dict(torch.load('checkpoint_actor.pth'))\n",
    "critic_local.load_state_dict(torch.load('checkpoint_critic.pth'))\n",
    "update_targets(critic_local, critic_target)\n",
    "update_targets(actor_local, actor_target)    \n",
    "scores, avgs = ddpg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0d0c69aac8>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the scores from all the runs\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(1, len(scores_from_all_runs)+1), scores_from_all_runs)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Test Trained Agent in the Environment\n",
    "\n",
    "Once this cell is executed, we can watch the agent's performance.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total score (averaged over agents) this episode: 35.21199921295047\n",
      "Total steps in this episode: 1001\n"
     ]
    }
   ],
   "source": [
    "#Load the previous trained weights\n",
    "#Need to turn on the GPU to even test it. Otherwise torch load results in error. \n",
    "actor_local.load_state_dict(torch.load('checkpoint_actor.pth'))\n",
    "critic_local.load_state_dict(torch.load('checkpoint_critic.pth'))\n",
    "\n",
    "env_info = env.reset(train_mode=False)[brain_name]     # reset the environment    \n",
    "states = env_info.vector_observations                  # get the current state (for each agent)\n",
    "scores = np.zeros(num_agents)                          # initialize the score (for each agent)\n",
    "steps = 0\n",
    "while True:\n",
    "    actions = agent(states, add_noise=False) \n",
    "    env_info = env.step(actions)[brain_name]           # send all actions to tne environment\n",
    "    next_states = env_info.vector_observations         # get next state (for each agent)\n",
    "    rewards = env_info.rewards                         # get reward (for each agent)\n",
    "    dones = env_info.local_done                        # see if episode finished\n",
    "    scores += env_info.rewards                         # update the score (for each agent)\n",
    "    states = next_states                               # roll over states to next time step\n",
    "    steps += 1\n",
    "    if np.any(dones):                                  # exit loop if episode finished\n",
    "        break\n",
    "print('Total score (averaged over agents) this episode: {}'.format(np.mean(scores)))\n",
    "print('Total steps in this episode: {}'.format(steps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When finished, you can close the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drlnd",
   "language": "python",
   "name": "drlnd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
